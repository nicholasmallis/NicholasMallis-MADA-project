---
title: "Project Part 2"
author: "Nicholas Mallis"
date: "10/5/2021"
output: html_document
---
#Introduction

Several sources have reported the relationship between education level and COVID-19 vaccination the individual level using data from surveys and qualitative research. KHN released a report on June 11 that outlines the profile of the unvaccinated. They state that “compared to those who have received a covid-19 vaccine, unvaccinated adults are younger, less educated, more likely to be republicans, people of color, and uninsured.” The complete report can be found here. https://www.kff.org/coronavirus-covid-19/poll-finding/kff-covid-19-vaccine-monitor-profile-of-the-unvaccinated/ Although this has been examined using surveys from individual participants on a smaller scale, there are no current reports or published papers that have studied this relationship using aggregate data from all counties in the US. 

The following analysis aims to examine the relationship between education level and vaccination rate (for people over age 12) at the county level for all counties in the 50 US states. I use public data from CDC on vaccination rates by county and other county characteristics that are available through several different sources on the USDA’s Economic Research website for the analysis. The proposed analysis could provide more information on the association between education and vaccination rate on a larger scale. 


#Methods: The Data Sources

####Main Outcome
The main outcome for this analysis is percent of eligible people (age 12+) in a county that have been fully vaccinated. It was obtained from the CDC’s open-source dataset, "COVID-19 Vaccinations in the United States, County." Here is the link to this dataset -> https://data.cdc.gov/Vaccinations/COVID-19-Vaccinations-in-the-United-States-County/8xkx-amqh This dataset “represents all vaccine partners including jurisdictional partner clinics, retail pharmacies, long-term care facilities, dialysis centers, Federal Emergency Management Agency and Health Resources and Services Administration partner sites, and federal entity facilities.” The data represents vaccination percentages up to 09/29/2021.

####Main Exposure:
The main exposure for the analysis is percent of adults in each county who have a bachelors degree or higher. The most current county level data on education is available on the USDA’s Economic Research website and can be found if you click here -> https://www.ers.usda.gov/data-products/county-level-data-sets/download-data/ This dataset includes information on education level for all years and I will subset the data to only include observations from the most current year. The most current calculations of education level by county are 5- year averages based on 2015-2019 and they come from the Census Bureau’s American Community Survey. 

####Covariates:
There are other possible confounders that we are interested in examining including poverty, unemployment, median household income, locality (urban or rural) and health insurance rate. In order to obtain this information, I pull in data from a few more sources. The first three variables are available through the USDA Economic Research Service as well, but in different datasets.  They can be found here on the USDA website -> https://www.ers.usda.gov/data-products/county-level-data-sets/download-data/ The county poverty estimates are model-based estimates from the U.S. Census Bureau's Small Area Income and Poverty Estimate (SAIPE) program. The county unemployment rates are from the Bureau of Labor Statistics (BLS) Local Area Unemployment Statistics (LAUS) program. The county median household income variable comes from the U.S. Census Bureau's Small Area Income and Poverty Estimate (SAIPE) program. The locality (urban or rural) variable comes from from the Rural-Urban Continuum Codes Dataset which is also managed by USDA. This can be found here -> https://www.ers.usda.gov/data-products/rural-urban-continuum-codes/


#Methods: Data Importing, Cleaning, and Wrangling

In order to explore the possible relationship between education level and vaccination rates at the county level, I first pull in data from several different sources and merge them together. Most county level data are tagged with a Federal Information Processing Standards (FIPS) number. This will be the ID variable for merging these datasets. The following chunks of code load the packages neccessary for data importing and proccessing. They also sets paths to the different datasets within the repository. Note: I used message=false in the RMD chunk to supress the output for ease of reading. 
```{r message=FALSE}
###############################
#processing script
#this script loads the raw data, processes and cleans it 
#and saves it as Rds file in the processed_data folder

#the following code loads different packages and also installs them as needed
#if they aren't already installed
mypackages<-c("readr", "plyr", "dplyr", "here", "tidyverse", "gridExtra", "tidyr", "gridExtra", "robustbase", "usmap", "ggplot2" )

for (p in mypackages){
  if(!require(p, character.only = TRUE)){
    install.packages(p)
    library(p, character.only = TRUE)
  }
}

#load needed packages. 
#library(readr) 
#library(plyr)
#library(dplyr)
#library(here) 
#library(tidyverse)
#library(gridExtra)



#path to different datasets
#note the use of the here() package and not absolute paths
data_location1 <- here::here("data","raw_data","countyvaccination.csv")
data_location2 <- here::here("data","raw_data","Education-2.csv")
data_location3 <- here::here("data","raw_data","ruralurbancodes2013-3.csv")
data_location4 <- here::here("data","raw_data","PovertyEstimates.csv")
data_location5 <- here::here("data","raw_data","Unemployment.csv")

```

Now we load in all the datasets from the different paths.
```{r}
#Loading in all five datasets for the outcome and predictors
vax <- read.csv(data_location1)
ed <- read.csv(data_location2)
locality <- read.csv(data_location3)
poverty <- read.csv(data_location4)
unemployment <- read.csv(data_location5)

```

Below I take a quick glimpse at the data. Note that FIPS is called something slightly different in each dataset. I will need to change the names to get them to match before the merge.
```{r echo=FALSE}
#take a look at the datasets
dplyr::glimpse(vax)
dplyr::glimpse(ed)
dplyr::glimpse(locality)
dplyr::glimpse(poverty)
```
Everything looks pretty good on all four. Now I print parts of them to see what they look like. Due to the large output results, I supressed the printing.
```{r results='hide'}
head(vax)
tail(ed)
head(locality)
tail(poverty)
```

###Checking/Cleaning Datasets Before Merging:
Before merging the datasets, I subset each dataset to only what is needed, starting with the vaccination data. The main outcome will be percent of eligible people (age 12+) in a county that have been fully vaccinated. We will also pull in the FIPS that will be used for merging,  metro status (which will tell us if the county is metro or non metro), county name, and state. After subsetting these variables, I do some quick data management by changings some unknowns to NA's and also convert some character variables to numeric. Note: The first chunk of comments and code that is commented out shows a step that I had to do in another R script before adding the vaccination data to my repository. The data was too large and causing problems with GitKraken. 
```{r}

#But before that let's get this to only the most recent data. So we'll subset today
#vax <- vax[ which(vax$Date== "09/29/2021"), ]
#NOTE: I HAD TO DO THIS STEP OUTSIDE OF THE PROJECT BECAUSE
#THE FILE WAS TOO BIG TO INCLUDE IN THE REPO

#glimpse(vax) I commented this out for ease of reading the RMD

#subsetting waht we need
myvars <- c("FIPS", "Series_Complete_12PlusPop_Pct","Metro_status", "Recip_County", "Recip_State")
vax <- vax[myvars]


#after printing this, we see that the FIPS is a character variable with #some marked as UNK. i'd like to convert this to a numeric variable and get #the unknowns to be NA's. Let's start with the NA's

vax$FIPS[vax$FIPS=='UNK'] <- NA

#now let's convert to numeric.
#and while we're at it, we'll go ahead an convert Series_Complete_12PlusPop_Pct to numeric as well

vax$FIPS <- as.numeric(vax$FIPS)
vax$Series_Complete_12PlusPop_Pct <- as.numeric(vax$Series_Complete_12PlusPop_Pct)


#checking. looks good
head(vax)
glimpse(vax)
```

In a similar manner, I read in the education data and subset the variables needed (FIPS.Code and percent of adults with a bachelors degree or higher). There is one extra step here though. I rename the variable FIPS.Code to FIPS. This matches the variable from the vaccine dataset and will allow me to merge effectively.
```{r}
#now let's look at the data on the main exposure
#glimpse(ed) commenting this out for ease of reading RMD 

#subsetting what we need
myvars2 <- c("FIPS.Code", "Percent.of.adults.with.a.bachelor.s.degree.or.higher..1990")
ed <- ed[myvars2]

#print(ed) I comment this out to make the document shorter

#looks like FIPS.Code is already numeric, but we need need perecent adults with bachelor to be numeric
#let's go ahead and convert that.
#ed$FIPS.Code <- as.numeric(ed$FIPS.Code)

#trying to convert to character
ed$FIPS.Code <- as.character(ed$FIPS.Code)


#since we'll be merging in FIPS, let's go ahead and change the var name "FIPS.Code"
names(ed)[1] <- "FIPS"

#checking. looks good
glimpse(ed)
head(ed)
```


Now I load in median income which comes from the unemployment dataset. The data includes other years, but I only want information from the most recent estimates so I subset the FIPS_Code, Unemployment_rate_2020, and Median_Household_Income_2019. The most recent median household income estimate calculations from this dataset are from year 2019. I would have used 2020 if it were available.
```{r}
#glimpse(unemployment) commenting out for ease of reading

#subsetting waht we need
myvars3 <- c("FIPS_Code", "Unemployment_rate_2020", "Median_Household_Income_2019" )
unemployment <- unemployment[myvars3]

#since we'll be merging in FIPS, let's go ahead and change the var name "FIPS.Code"
names(unemployment)[1] <- "FIPS"

#converting to character due to issues
#trying to convert to character
unemployment$FIPS <- as.character(unemployment$FIPS)


#checking
glimpse(unemployment)
head(unemployment)
```

And finally we pull in data to obtain the most recent percentage of people of all ages in poverty and use similar tactics as before to get the data in working order.
```{r}
#next dataset...Poverty Estimates. We want PCTPOVALL_2019 which is the
#Estimated percent of people of all ages in poverty 2019

#glimpse(poverty) commenting this out

#subsetting waht we need
myvars4 <- c("FIPStxt", "PCTPOVALL_2019" )
poverty <- poverty[myvars4]

#since we'll be merging in FIPS, let's go ahead and change the var name "FIPS.Code"
names(poverty)[1] <- "FIPS"

#converting to character due to issues
#trying to convert to character
poverty$FIPS <- as.character(poverty$FIPS)



#checking
glimpse(poverty)
head(poverty)

```

###The Merge:
Below we merge all of the datasets together before analysis.
```{r}
#The merge. I really wanted to merge all in one step and
#I was having trouble. I ended up finding this code using Reduce that #worked though.

#complete <- Reduce(function(x, y) merge(x, y, all=TRUE), list(vax, ed, unemployment, poverty))

#There ended up being some possible problems with what I ran above so I do it again below in several steps


complete1 <- merge(vax, ed)

glimpse(complete1)
complete2 <- merge(unemployment, poverty)
glimpse(complete2)
complete <- merge(complete1, complete2)

#checking. looks good!
glimpse(complete)
```

###More Data Management:
It is looking pretty good, but there are still a few things that need to be done prior to analysis. The following chunk of code executes some data processing steps. First, I convert income to a numeric variable, but have to remove the commas in the character string while converting. Second, right now the data includes US territories. For the purposes of this analysis, I am only interested in using data from the 50 states. I subset the data to ony include the 50 states and DC. Finally, some of the variable names used in the datasets that I pulled from were long and will not be great to work with during the analysis stage. Using the names() function, I rename all the variables as necessary.
```{r}

#It looks like Median Household income is still a character. Let's fix that.
#But first we need to remove the delimiter
complete$Median_Household_Income_2019 <- as.numeric(gsub(",","",complete$Median_Household_Income_2019))

glimpse(complete)

#now let's look at some locations stuff. i'm not particulary interested in including data from US territories. #i really only want to look at states. 
#we might need to do some subsetting. let's table state and see what we get...
table(complete$Recip_State) 

#this subsets the data to only having the states we need
complete <- complete[which(complete$Recip_State != 'AS'
                           &
                             complete$Recip_State != 'FM'
                           &
                             complete$Recip_State != 'GY'
                           &
                             complete$Recip_State != 'GU'
                           &
                             complete$Recip_State != 'MP'
                           &
                             complete$Recip_State != 'PW'
                           &
                             complete$Recip_State != 'PR'
                           &
                             complete$Recip_State != 'MH'
                           &
                             complete$Recip_State != 'VI'
), ]

#checking. looks good!
table(complete$Recip_State)



#before we continue, i really need to change some of these variable names. they are just too long!
names(complete)[2] <- "pct_vax"
names(complete)[3] <- "locality"
names(complete)[4] <- "county"
names(complete)[5] <- "state"
names(complete)[6] <- "pct_bachelors"
names(complete)[7] <- "unemployment"
names(complete)[8] <- "median_income"
names(complete)[9] <- "pct_poverty"

#checking. looks good!
glimpse(complete)
```
#Exploratory Analysis 
In the following section, I examine each variable with a five number summary and calculate the percent missing of each variable. I also plot histograms to check the distribution of each variable. For locality, the one categorcial variable, I use a table statement nested within a prop.table to calculate the percentages and plot a stratified frequency chart.
```{r}


#now let's do a five number summary for each continuous variable
fivenum(complete$pct_vax)
fivenum(complete$pct_bachelors)
fivenum(complete$unemployment)
fivenum(complete$median_income)
fivenum(complete$pct_poverty)

#now let's look at the categorical variable
table(complete$locality)
prop.table(table(complete$locality))

#now let's explore what percent of each variable is missing
#we see here that there is about 1% missing from most of our variables, which isn't so bad
colMeans(is.na(complete))

#let's take a quick look at the bottom of the new dataset. here we see where a lot of the missing comes from. it looks like everything is missing from these last 50 observations. i am going to take note of this, but delete them.
tail(complete, n=50)


#here i subset again
complete <- complete[!is.na(complete$FIPS), ]



```

##Histogram of Main Outcome: Percent Vaccinated
The figure below is a histogram of the outcome variable, percent vaccinated in each county. Here we see that the data is skewed with a lot of observations close to 0%. The median appears to be close to %48.
```{r, warning=FALSE}
#Now some plotting of distribution for each variable


#here we do % vaccinated
a <- complete %>% ggplot(aes(x=pct_vax)) + geom_histogram(fill="red", binwidth = 5.) + labs(title= "Histogram of Percent Vaccinated by County (USA, 09/29/2021)") + xlab("Histogram of Percent Vaccinated by County") +  ylab("Count") + theme_classic()
a
```

##Histogram of Main Predictor: Percent With Bachelors Degree
The figure below is a histogram of the main predictor variable, percent with a bachelors degree in each county. Here we see that the data is skewed with a tail to the right.
```{r, warning=FALSE}
#here we do % bachelors
b <- complete %>% ggplot(aes(x=pct_bachelors)) + geom_histogram(fill="blue", binwidth = 5) + xlim(0, 75) + labs(title= "Histogram of Percent with Bachelors Degree by County (USA)") + xlab("Histogram of Percent with Bachelors by County") +  ylab("Count") + theme_classic() 
b
```


##Histograms of Other Continuous Covariates:
Here we can see that the other continuous variables do not appear to be normally distributed. Due to this, we will report medians and IQR's in our summary statistics table.


```{r echo=FALSE, warning=FALSE}
#here we do % unemployment
c <- complete %>% ggplot(aes(x=unemployment)) + geom_histogram(fill="green", binwidth = 5) + xlim(0, 75) + labs(title= "Histogram of Unemployment Rate by County (USA)") + xlab("Histogram of Unemployment Rate by County") +  ylab("Count") + theme_classic()
c

#here we do % poverty
d <- complete %>% ggplot(aes(x=pct_poverty)) + geom_histogram(fill="purple", binwidth = 5) + xlim(0, 75) + labs(title= "Histogram of Poverty Rate by County (USA)") + xlab("Histogram of Poverty Rate by County") +  ylab("Count") + theme_classic()
d

#here we do median income
e <- complete %>% ggplot(aes(x=median_income)) + geom_histogram(fill= "orange", binwidth = 10000) + labs(title= "Histogram of Median Income by County (USA)") + xlab("Histogram of Median Income by County") +  ylab("Count") + theme_classic()
e

```

#More Data Management
The following code performs some data management in order to summarize each continuous variable.

```{r}


num_cols <- unlist(lapply(complete, is.numeric))         # identify numeric columns
complete_num <- complete[ , num_cols]                    #subset numeric columns of data
          


#here use a function to perform multiple calculations on the variables
#to get the median and IQR. notice that I use a transposition to get 
#it in working order
table <- as.data.frame( t(sapply(complete_num, function(x) c(
                         "Median" = median(x, na.rm = T),
                         "25TH PCT" = unname(quantile(x, 0.25, na.rm = T)),
                         "75TH PCT" = unname(quantile(x, 0.75, na.rm = T)))
                    
                  
)))
 
#below I do a some more data management to add commas to large figures
table$Median <- prettyNum(table$Median, big.mark = ",", scientific = FALSE) 
table$`25TH PCT` <- prettyNum(table$`25TH PCT`, big.mark = ",", scientific = FALSE) 
table$`75TH PCT` <- prettyNum(table$`75TH PCT`, big.mark = ",", scientific = FALSE) 

#i also combine the 25th percentile and 75th into a character string seperated by a "-"
table$IQR <- paste(table$`25TH PCT`, table$`75TH PCT`, sep = "-")

#then i add parentheses around it using this function
addparentheses <- function(x){paste("(", x, ")")}
table$IQR <- addparentheses(table$IQR)

# we don't need the first row or middle colums so we delete them
table <- table[-c(1), -c(2,3)]
rownames(table) <-  c("Percent Vaccinated over 12 years", "Percent with Bachelors Degree or Higher", "Unemployment Rate (%)", "Median Household Income", "Poverty Rate (%)") 
```

##Table of Summary Statistics:
The table below summarizes the median and interquartile range for each continous variable in the analysis. 
```{r, echo=FALSE}
#printing
print(table)

#this table will likely end up in the final paper so saved it as a file
summarytable_file = here("results", "summarytable.rds")
saveRDS(table, file = summarytable_file)
```

Now I  display the saved file for an improved aesthetic.
```{r summarytable,  echo=FALSE}
resulttable=readRDS("../../results/summarytable.rds")
knitr::kable(resulttable, caption = 'Table 1. Summary Statistics for US Counties (n=3,142)')
```


##Plotting The One Categorical Variable: Locality
```{r, results='hide' , warning=FALSE, echo=FALSE, message=FALSE }
#and finally we look at locality
f <- complete %>% ggplot(aes(x=locality, fill=locality)) + geom_bar() +
labs(title= "Bar Chart of Frequency of Counties by Locality (USA)") + xlab("Locality") +  ylab("Count") + theme_classic()

#looks like we've got some missing here...
table(complete$locality)
#let's convert the blanks to missing
complete$locality[complete$locality == ""] <- NA
```

```{r, echo=FALSE}
#let's try this one again, but without the missing observations
g <- ggplot(data=subset(complete, !is.na(locality)), aes(x=locality, fill=locality)) + geom_bar() +
labs(title= "Bar Chart of Frequency of Counties by Locality (USA)") + xlab("Locality") +  ylab("Count") + theme_classic()
g
```

#Further Exploratory Analysis: Main Research Question 
In the next section, I present scatterplots with linear regression overlays to visualize possible univariate associations between the continuous predictors and outcome. I also present a strafied boxplot by our one categorical predictor, locality. First, I plot percent with bachelors degree or higher vs percent vaccinated. From the scatterplot, we see that there seems to be a positive association. As county bachelors degree percentages increase, percent vaccinated increases. 
```{r, warning=FALSE, message=FALSE}

#now let's do a simple scatter plot of our main predictor and outcome to explore the relationship
p1 <- complete %>% ggplot(aes(x=pct_bachelors, y=pct_vax)) + geom_point(color="red") + geom_smooth(method='lm', color="black") + labs(title= "Scatterplot of Percent with Bachelors Degree vs Percent Vaccinated", subtitle = ("All Counties, USA")) + xlab("Percent of County with a Bachelors Degree or Higher") +  ylab("Percent of County Vaccinated (12 Years +)") + theme_classic()

print(p1)

#I think this figure might end up in the final paper so I am going to save it as a PNG...
figure_file = here("results","resultfigure1.png")
ggsave(filename = figure_file, plot=p1)

#at first glance, there appears to be a linear relationship between our predictor and outcome,
#but it looks like there a lot of 0s for our outcome (% vaccinated over 12). Let's take a closer look.

#it looks like we have 268 of the counties with 0% vaccination. i'm wondering if this could be an error or 
#if some counties haven't reported.
count <- length(which(complete$pct_vax == 0))      

count
```


#Further Exploratory Analysis: Covariates
From the first scatterplot, we see that there seems to be a positive association between median household income and vaccination rate. As median household income increases, percent vaccinated increases. This is opposite with poverty rate. As poverty rate increases, percent vaccinated decreases. Regarding unemployment, there is a slight positive association with percent vaccinated. Based the on box plots stratifed by locality, we see that counties labeled as metro have a higher median vaccination rate compared with those labeled as non-metro.


```{r, warning=FALSE, echo=FALSE, message=FALSE}

#now some more exploration with other variables
#let's look at income...

p2 <- complete %>% ggplot(aes(x=median_income, y=pct_vax)) + geom_point(color="blue") + geom_smooth(method='lm', color="black") + labs(title= "Scatterplot of Median Income vs Percent Vaccinated", subtitle = ("All Counties, USA")) + xlab("Median County Income") +  ylab("Percent of County Vaccinated (12 Years +)") + theme_classic()
p2

p3 <- complete %>% ggplot(aes(x=pct_poverty, y=pct_vax)) + geom_point(color="green") + geom_smooth(method='lm', color="black") + labs(title= "Scatterplot of Percent of County in Poverty vs Percent Vaccinated", subtitle = ("All Counties, USA")) + xlab("Percent of County in Poverty") +  ylab("Percent of County Vaccinated (12 Years +)") + theme_classic()
p3

p4 <- complete %>% ggplot(aes(x=unemployment, y=pct_vax)) + geom_point(color="purple") + geom_smooth(method='lm', color="black") + labs(title= "Scatterplot of Unemployment Rate in County vs Percent Vaccinated", subtitle = ("All Counties, USA")) + xlab("Unemployment Rate in County") +  ylab("Percent of County Vaccinated (12 Years +)") + theme_classic()
p4

p5 <- ggplot(data=subset(complete, !is.na(locality)), aes(x=locality, y=pct_vax, fill=locality)) + geom_boxplot() + labs(title= "Boxplot of Locality vs Percent Vaccinated", subtitle = ("All Counties, USA")) + xlab("Locality") +  ylab("Percent of County Vaccinated (12 Years +)") + theme_classic()
p5

```

#Tabling Percent Vaccinated by Locality
```{r}
#define quantiles of interest
q = c(.25, .75)

#calculate quantiles by grouping variable
locality_table <- complete %>%
  group_by(locality) %>%
  summarize(median = round(median(pct_vax, na.rm=TRUE), 1),
            quant25 = round(quantile(pct_vax, probs = q[1], na.rm=TRUE), 1), 
            quant75 = round(quantile(pct_vax, probs = q[2], na.rm= TRUE), 1))



#i also combine the 25th percentile and 75th into a character string seperated by a "-"
locality_table$IQR <- paste(locality_table$quant25, locality_table$quant75, sep = "-")

#then i add parentheses around it using this function
addparentheses <- function(x){paste("(", x, ")")}
locality_table$IQR <- addparentheses(locality_table$IQR)


# we don't need the first row or middle colums so we delete them
locality_table <- locality_table[-c(3), -c(3,4)]

names(locality_table)[1] <- "Locality"
names(locality_table)[2] <- "Median Vaccination Rate (%)"

locality_table

#this table might end up in the final paper so saved it as a file
summarytable_file2 = here("results", "summarytable2.rds")
saveRDS(locality_table, file = summarytable_file2)
```

Now I  display the saved file for an improved aesthetic. 
```{r summarytable2,  echo=FALSE}
resulttable=readRDS("../../results/summarytable2.rds")
knitr::kable(resulttable, caption = 'Table 2. Median and Interquartile Range of Percent Vaccinated by Locality, US Counties (n=3,142)')
```

##Mapping:
Finally, I use the usmap package to produce a figure that represents vaccination rates for each county. Here we can see that the largest cluster of counties with low vaccination rates is in Texas and takes up most of the states surface area. 

```{r}


practice <- plot_usmap(regions = "counties") + 
  labs(title = "US Counties",
       subtitle = "This is a blank map of the counties of the United States.") + 
  theme(panel.background = element_rect(color = "black", fill = "lightblue"))

#here we see that the countypop is a built in dataset within R. we use this below to merge with our dataset.
map <- merge(countypop, complete)

#then we use this new dataset to plot
mapplot <- plot_usmap(data = map, values = "pct_vax") +
  scale_fill_continuous(name = "Percent Vaccinated", label = scales::comma, type = "viridis") + theme(legend.position = "right")

#adding a title and theme adjustment
mapplot + ggtitle("Map of US County Vaccination Rates for Residents Age 12+ by 09/29/2021") +
  theme(panel.background = element_rect(color = "black", fill = "white")) 

#I think this figure might end up in the final paper so I am going to save it as a PNG...
figure_file = here("results","resultfigure2.png")
ggsave(filename = figure_file, plot=mapplot)


```


Finally, we save our dataset to the processed_data folder below for future analysis.

```{r}
# location to save file
save_data_location <- here::here("data","processed_data","processeddata.rds")

saveRDS(complete, file = save_data_location)

```

